[32m2025-03-21 06:02:52.964[39m | [1mINFO    [22m | [36m__main__[39m:[36mlog[39m:[36m72[39m - [1m[0] start loading arguments
[32m2025-03-21 06:02:52.965[39m | [1mINFO    [22m | [36m__main__[39m:[36mlog[39m:[36m72[39m - [1m[0] ****************************************
[32m2025-03-21 06:02:52.965[39m | [1mINFO    [22m | [36m__main__[39m:[36mlog[39m:[36m72[39m - [1m[0] rank                           3
[32m2025-03-21 06:02:52.965[39m | [1mINFO    [22m | [36m__main__[39m:[36mlog[39m:[36m72[39m - [1m[0] dim                            8
[32m2025-03-21 06:02:52.965[39m | [1mINFO    [22m | [36m__main__[39m:[36mlog[39m:[36m72[39m - [1m[0] batch_size                     32
[32m2025-03-21 06:02:52.965[39m | [1mINFO    [22m | [36m__main__[39m:[36mlog[39m:[36m72[39m - [1m[0] tau                            5
[32m2025-03-21 06:02:52.965[39m | [1mINFO    [22m | [36m__main__[39m:[36mlog[39m:[36m72[39m - [1m[0] lr                             0.001
[32m2025-03-21 06:02:52.966[39m | [1mINFO    [22m | [36m__main__[39m:[36mlog[39m:[36m72[39m - [1m[0] epoch                          3
[32m2025-03-21 06:02:52.966[39m | [1mINFO    [22m | [36m__main__[39m:[36mlog[39m:[36m72[39m - [1m[0] ****************************************
[32m2025-03-21 06:02:54.905[39m | [1mINFO    [22m | [36m__main__[39m:[36mlog[39m:[36m72[39m - [1m[0] start training
Traceback (most recent call last):
  File "/home/xyq/SubScaf/SS_simple.py", line 183, in <module>
    SubScaf(args)
  File "/home/xyq/SubScaf/SS_simple.py", line 148, in SubScaf
    loss = mse_loss(output, y)
  File "/home/xyq/miniconda3/envs/diloco/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/xyq/miniconda3/envs/diloco/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/xyq/miniconda3/envs/diloco/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 535, in forward
    return F.mse_loss(input, target, reduction=self.reduction)
  File "/home/xyq/miniconda3/envs/diloco/lib/python3.9/site-packages/torch/nn/functional.py", line 3339, in mse_loss
    return torch._C._nn.mse_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction))
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
Traceback (most recent call last):
  File "/home/xyq/SubScaf/SS_simple.py", line 183, in <module>
    SubScaf(args)
  File "/home/xyq/SubScaf/SS_simple.py", line 148, in SubScaf
    loss = mse_loss(output, y)
  File "/home/xyq/miniconda3/envs/diloco/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/xyq/miniconda3/envs/diloco/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/xyq/miniconda3/envs/diloco/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 535, in forward
    return F.mse_loss(input, target, reduction=self.reduction)
  File "/home/xyq/miniconda3/envs/diloco/lib/python3.9/site-packages/torch/nn/functional.py", line 3339, in mse_loss
    return torch._C._nn.mse_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction))
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!