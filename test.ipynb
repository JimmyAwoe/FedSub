{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 10\n",
    "r = 5 \n",
    "n = 1000\n",
    "def Coordinate_descend_genep(d, r):\n",
    "    ide = np.eye(d)\n",
    "    col_num = np.arange(d)\n",
    "    select_col = np.random.choice(col_num, r, replace=False)\n",
    "    sign = np.random.choice([-1, 1], r)\n",
    "    P = np.sqrt(d / r) * ide[:, select_col] * sign\n",
    "    return P\n",
    "sum_ptp = np.zeros((r, r))\n",
    "sum_ppt = np.zeros((d, d))\n",
    "sum_p = np.zeros((d, r))\n",
    "for i in range(n):\n",
    "    p = Coordinate_descend_genep(d, r)\n",
    "    sum_p += p\n",
    "    sum_ptp += p.T @ p\n",
    "    sum_ppt += p @ p.T\n",
    "sum_ptp /= n\n",
    "sum_ppt /= n\n",
    "sum_p /= n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 5\n",
    "r = 3\n",
    "n = 1000\n",
    "def Spherical_smoothing_genep(d, r):\n",
    "    z = np.random.randn(d, d)\n",
    "    Q, R = np.linalg.qr(z)\n",
    "    D = np.diag(np.sign(np.diag(R)))\n",
    "    Q = Q @ D\n",
    "    R = D @ R\n",
    "    assert np.allclose(Q @ R, z, atol=1e-7), \"the QR decomposion is not accuracy\"\n",
    "    P = np.sqrt(d / r) * Q[:, :r]\n",
    "    return P\n",
    "sum_ptp = np.zeros((r, r))\n",
    "sum_ppt = np.zeros((d, d))\n",
    "for i in range(n):\n",
    "    p = Spherical_smoothing_genep(d, r)\n",
    "    sum_ptp += p.T @ p\n",
    "    sum_ppt += p @ p.T\n",
    "sum_ptp /= n\n",
    "sum_ppt /= n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.02078913,  0.00281439,  0.00390279,  0.00926093, -0.02146264],\n",
       "       [ 0.00281439,  1.01920871, -0.00904708,  0.01339887, -0.01596834],\n",
       "       [ 0.00390279, -0.00904708,  0.97774856, -0.00870662,  0.01479128],\n",
       "       [ 0.00926093,  0.01339887, -0.00870662,  0.98127913,  0.00355863],\n",
       "       [-0.02146264, -0.01596834,  0.01479128,  0.00355863,  1.00097447]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_ppt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    LlamaConfig,\n",
    "    LlamaForCausalLM,\n",
    "    AutoTokenizer,\n",
    ")\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xuyuqi/.conda/envs/minimind/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:606: UserWarning: `pad_token_id` should be positive but got -1. This will cause errors when batch generating, if there is padding. Please set `pad_token_id` explicitly as `model.generation_config.pad_token_id=PAD_TOKEN_ID` to avoid errors in generation\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "config = LlamaConfig.from_pretrained(\"./configs/llama_60m.json\")\n",
    "model = LlamaForCausalLM(config)\n",
    "optim = torch.optim.SGD(model.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def print_name(model):\n",
    "    #for name, child in model.named_children():\n",
    "        #if isinstance(child, nn.Linear):\n",
    "            #print(name)\n",
    "        #else:\n",
    "            #print_name(child)\n",
    "#print_name(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import SubScafLinear, SubScafSGD\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "def gene_random_matrix(in_dim, out_dim):\n",
    "    return torch.randn(in_dim, out_dim) / math.sqrt(out_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_mat = gene_random_matrix(512, 64).to(\"cuda:0\")\n",
    "module = nn.Linear(512, 512, device='cuda:0')\n",
    "model = SubScafLinear(64, comp_mat, module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_groups = model.parameters()\n",
    "optimizer = SubScafSGD(param_groups, \n",
    "                        lr=0.001, \n",
    "                        tau=16, \n",
    "                        compression_dim=64,\n",
    "                        )\n",
    "data = torch.randn(1024, 512).to('cuda:0')\n",
    "label = torch.randn(1024, 512).to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 512])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Coordinate_descend_genep(dim, comp_dim, n=1):\n",
    "    assert dim >= comp_dim, \"compression dimension must be smaller than dimension\"\n",
    "    sum_p = torch.zeros(dim, comp_dim) \n",
    "    for _ in range(n):\n",
    "        ide = torch.eye(dim)\n",
    "        select_col = torch.randperm(dim)[:comp_dim]\n",
    "        sign = torch.randint(0, 2, (comp_dim, ))\n",
    "        sign = sign * 2 - 1\n",
    "        P = ide[:, select_col] * sign\n",
    "        sum_p += P\n",
    "    P = sum_p / n\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 9, 8])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "torch.randperm(3)\n",
    "np.random.choice(10, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Coordinate_descend_genep(10, 5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.T @ a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minimind",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
