W0701 11:05:31.330000 559029 site-packages/torch/distributed/run.py:766] 
W0701 11:05:31.330000 559029 site-packages/torch/distributed/run.py:766] *****************************************
W0701 11:05:31.330000 559029 site-packages/torch/distributed/run.py:766] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0701 11:05:31.330000 559029 site-packages/torch/distributed/run.py:766] *****************************************
2025-07-01 11:05:36.574 | INFO     | utils.common:log:12 - Process group initialize
2025-07-01 11:05:36.574 | INFO     | utils.common:log:12 - ****************************************
2025-07-01 11:05:36.574 | INFO     | utils.common:log:12 - Start training with arguments
2025-07-01 11:05:36.574 | INFO     | utils.common:log:12 - lr                             0.001
2025-07-01 11:05:36.574 | INFO     | utils.common:log:12 - batch_size                     64
2025-07-01 11:05:36.574 | INFO     | utils.common:log:12 - total_batch_size               64
2025-07-01 11:05:36.574 | INFO     | utils.common:log:12 - max_length                     1024
2025-07-01 11:05:36.574 | INFO     | utils.common:log:12 - num_training_steps             100
2025-07-01 11:05:36.574 | INFO     | utils.common:log:12 - grad_clip                      0.0
2025-07-01 11:05:36.574 | INFO     | utils.common:log:12 - warmup                         1000
2025-07-01 11:05:36.574 | INFO     | utils.common:log:12 - constant_lr                    True
2025-07-01 11:05:36.575 | INFO     | utils.common:log:12 - seed                           42
2025-07-01 11:05:36.575 | INFO     | utils.common:log:12 - mixed_precision                bf16
2025-07-01 11:05:36.575 | INFO     | utils.common:log:12 - comp_dim                       4096
2025-07-01 11:05:36.575 | INFO     | utils.common:log:12 - tau                            10
2025-07-01 11:05:36.575 | INFO     | utils.common:log:12 - gene_method                    idx
2025-07-01 11:05:36.575 | INFO     | utils.common:log:12 - jump_certain_modules           False
2025-07-01 11:05:36.575 | INFO     | utils.common:log:12 - update_cp_freq                 50
2025-07-01 11:05:36.575 | INFO     | utils.common:log:12 - adaptive_cp_rate               1.0
2025-07-01 11:05:36.575 | INFO     | utils.common:log:12 - model_config                   configs/llama_60m.json
2025-07-01 11:05:36.575 | INFO     | utils.common:log:12 - optimizer                      fedavgsgd
2025-07-01 11:05:36.575 | INFO     | utils.common:log:12 - momentum                       0.0
2025-07-01 11:05:36.575 | INFO     | utils.common:log:12 - dampening                      0
2025-07-01 11:05:36.575 | INFO     | utils.common:log:12 - weight_decay                   0
2025-07-01 11:05:36.575 | INFO     | utils.common:log:12 - nesterov                       False
2025-07-01 11:05:36.575 | INFO     | utils.common:log:12 - per_layer_weight_update        False
2025-07-01 11:05:36.575 | INFO     | utils.common:log:12 - use_wandb                      False
2025-07-01 11:05:36.575 | INFO     | utils.common:log:12 - wandb_run_name                 real_lazy_update
2025-07-01 11:05:36.575 | INFO     | utils.common:log:12 - use_tqdm                       False
2025-07-01 11:05:36.575 | INFO     | utils.common:log:12 - use_log                        True
2025-07-01 11:05:36.575 | INFO     | utils.common:log:12 - mem_monitor                    False
2025-07-01 11:05:36.575 | INFO     | utils.common:log:12 - flash_attn                     False
2025-07-01 11:05:36.575 | INFO     | utils.common:log:12 - ckpt                           True
2025-07-01 11:05:36.575 | INFO     | utils.common:log:12 - measure_comm                   False
2025-07-01 11:05:36.575 | INFO     | utils.common:log:12 - measure_all                    True
2025-07-01 11:05:36.576 | INFO     | utils.common:log:12 - change_cd                      3000
2025-07-01 11:05:36.576 | INFO     | utils.common:log:12 - ****************************************
/home/xuyuqi/.conda/envs/minimind/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:606: UserWarning: `pad_token_id` should be positive but got -1. This will cause errors when batch generating, if there is padding. Please set `pad_token_id` explicitly as `model.generation_config.pad_token_id=PAD_TOKEN_ID` to avoid errors in generation
  warnings.warn(
/home/xuyuqi/.conda/envs/minimind/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:606: UserWarning: `pad_token_id` should be positive but got -1. This will cause errors when batch generating, if there is padding. Please set `pad_token_id` explicitly as `model.generation_config.pad_token_id=PAD_TOKEN_ID` to avoid errors in generation
  warnings.warn(
2025-07-01 11:05:40.644 | INFO     | utils.common:log:12 - 
LlamaForCausalLM(
  (model): LlamaModel(
    (embed_tokens): Embedding(32000, 512, padding_idx=31999)
    (layers): ModuleList(
      (0-7): 8 x LlamaDecoderLayer(
        (self_attn): LlamaAttention(
          (q_proj): Linear(in_features=512, out_features=512, bias=False)
          (k_proj): Linear(in_features=512, out_features=512, bias=False)
          (v_proj): Linear(in_features=512, out_features=512, bias=False)
          (o_proj): Linear(in_features=512, out_features=512, bias=False)
        )
        (mlp): LlamaMLP(
          (gate_proj): Linear(in_features=512, out_features=1376, bias=False)
          (up_proj): Linear(in_features=512, out_features=1376, bias=False)
          (down_proj): Linear(in_features=1376, out_features=512, bias=False)
          (act_fn): SiLU()
        )
        (input_layernorm): LlamaRMSNorm((512,), eps=1e-06)
        (post_attention_layernorm): LlamaRMSNorm((512,), eps=1e-06)
      )
    )
    (norm): LlamaRMSNorm((512,), eps=1e-06)
    (rotary_emb): LlamaRotaryEmbedding()
  )
  (lm_head): Linear(in_features=512, out_features=32000, bias=False)
)

2025-07-01 11:05:40.645 | INFO     | utils.common:log:12 - Total params: 58.07M
2025-07-01 11:05:40.645 | INFO     | utils.common:log:12 - Trainable params: 58.07M
/home/xuyuqi/.conda/envs/minimind/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  return fn(*args, **kwargs)
/home/xuyuqi/.conda/envs/minimind/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  return fn(*args, **kwargs)
/home/xuyuqi/.conda/envs/minimind/lib/python3.10/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/home/xuyuqi/.conda/envs/minimind/lib/python3.10/site-packages/torch/autograd/graph.py:824: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
2025-07-01 11:05:43.105 | INFO     | utils.common:log:12 - step: 1/100 Loss: 10.4706\10.471 Lr: 1.000e-3 Mem: 43.201 GB Throughput_tokens: 18602.2188
2025-07-01 11:05:44.182 | INFO     | utils.common:log:12 - step: 2/100 Loss: 10.4721\10.471 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 46674.7993
2025-07-01 11:05:45.240 | INFO     | utils.common:log:12 - step: 3/100 Loss: 10.4459\10.468 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 51027.1198
2025-07-01 11:05:46.256 | INFO     | utils.common:log:12 - step: 4/100 Loss: 10.4547\10.467 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 49700.0764
2025-07-01 11:05:47.314 | INFO     | utils.common:log:12 - step: 5/100 Loss: 10.4463\10.465 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 52459.6500
2025-07-01 11:05:48.372 | INFO     | utils.common:log:12 - step: 6/100 Loss: 10.4433\10.463 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 43000.8088
2025-07-01 11:05:49.409 | INFO     | utils.common:log:12 - step: 7/100 Loss: 10.4202\10.458 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 49797.2186
2025-07-01 11:05:50.410 | INFO     | utils.common:log:12 - step: 8/100 Loss: 10.4317\10.456 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 52650.4869
2025-07-01 11:05:51.469 | INFO     | utils.common:log:12 - step: 9/100 Loss: 10.4044\10.451 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 57919.9457
2025-07-01 11:05:52.567 | INFO     | utils.common:log:12 - step: 10/100 Loss: 10.4080\10.446 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 46382.5416
2025-07-01 11:05:52.567 | INFO     | utils.common:log:12 - ETA: 00:02:23 
2025-07-01 11:05:53.610 | INFO     | utils.common:log:12 - step: 11/100 Loss: 10.3968\10.441 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 55125.1750
2025-07-01 11:05:54.603 | INFO     | utils.common:log:12 - step: 12/100 Loss: 10.4014\10.437 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 50762.5919
2025-07-01 11:05:55.652 | INFO     | utils.common:log:12 - step: 13/100 Loss: 10.3861\10.432 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 46968.2240
2025-07-01 11:05:56.706 | INFO     | utils.common:log:12 - step: 14/100 Loss: 10.4025\10.429 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 43923.5818
2025-07-01 11:05:57.774 | INFO     | utils.common:log:12 - step: 15/100 Loss: 10.3889\10.425 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 40383.9293
2025-07-01 11:05:59.433 | INFO     | utils.common:log:12 - step: 16/100 Loss: 10.3928\10.422 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 26007.9394
2025-07-01 11:06:00.497 | INFO     | utils.common:log:12 - step: 17/100 Loss: 10.3633\10.416 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 47591.4710
2025-07-01 11:06:01.579 | INFO     | utils.common:log:12 - step: 18/100 Loss: 10.3623\10.411 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 44863.9488
2025-07-01 11:06:02.572 | INFO     | utils.common:log:12 - step: 19/100 Loss: 10.3357\10.403 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 53349.7538
2025-07-01 11:06:03.697 | INFO     | utils.common:log:12 - step: 20/100 Loss: 10.3337\10.396 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 50948.9498
2025-07-01 11:06:03.698 | INFO     | utils.common:log:12 - ETA: 00:01:42 
2025-07-01 11:06:04.769 | INFO     | utils.common:log:12 - step: 21/100 Loss: 10.3373\10.390 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 51062.9715
2025-07-01 11:06:05.763 | INFO     | utils.common:log:12 - step: 22/100 Loss: 10.3246\10.384 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 49364.1723
2025-07-01 11:06:06.773 | INFO     | utils.common:log:12 - step: 23/100 Loss: 10.3212\10.378 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 49454.0627
2025-07-01 11:06:07.787 | INFO     | utils.common:log:12 - step: 24/100 Loss: 10.3122\10.371 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 44972.7309
2025-07-01 11:06:08.797 | INFO     | utils.common:log:12 - step: 25/100 Loss: 10.2993\10.364 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 48931.3389
2025-07-01 11:06:09.806 | INFO     | utils.common:log:12 - step: 26/100 Loss: 10.3026\10.358 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 60382.1197
2025-07-01 11:06:10.816 | INFO     | utils.common:log:12 - step: 27/100 Loss: 10.3142\10.353 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 52167.0311
2025-07-01 11:06:11.829 | INFO     | utils.common:log:12 - step: 28/100 Loss: 10.2659\10.345 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 42916.1959
2025-07-01 11:06:12.846 | INFO     | utils.common:log:12 - step: 29/100 Loss: 10.2627\10.336 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 45693.9518
2025-07-01 11:06:13.901 | INFO     | utils.common:log:12 - step: 30/100 Loss: 10.2752\10.330 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 44971.2437
2025-07-01 11:06:13.901 | INFO     | utils.common:log:12 - ETA: 00:01:17 
2025-07-01 11:06:14.911 | INFO     | utils.common:log:12 - step: 31/100 Loss: 10.2625\10.324 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 47357.9157
2025-07-01 11:06:16.210 | INFO     | utils.common:log:12 - step: 32/100 Loss: 10.2656\10.318 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 40766.2915
2025-07-01 11:06:17.267 | INFO     | utils.common:log:12 - step: 33/100 Loss: 10.2442\10.310 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 41051.1954
2025-07-01 11:06:18.334 | INFO     | utils.common:log:12 - step: 34/100 Loss: 10.2326\10.303 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 41669.1839
2025-07-01 11:06:19.403 | INFO     | utils.common:log:12 - step: 35/100 Loss: 10.2316\10.296 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 51570.9803
2025-07-01 11:06:20.392 | INFO     | utils.common:log:12 - step: 36/100 Loss: 10.2267\10.289 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 54932.5111
2025-07-01 11:06:21.460 | INFO     | utils.common:log:12 - step: 37/100 Loss: 10.2014\10.280 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 46039.4337
2025-07-01 11:06:22.527 | INFO     | utils.common:log:12 - step: 38/100 Loss: 10.2078\10.273 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 55078.3155
2025-07-01 11:06:23.595 | INFO     | utils.common:log:12 - step: 39/100 Loss: 10.2085\10.266 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 43055.2266
2025-07-01 11:06:24.608 | INFO     | utils.common:log:12 - step: 40/100 Loss: 10.2241\10.262 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 49394.2435
2025-07-01 11:06:24.608 | INFO     | utils.common:log:12 - ETA: 00:01:04 
2025-07-01 11:06:25.663 | INFO     | utils.common:log:12 - step: 41/100 Loss: 10.1786\10.254 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 52923.3608
2025-07-01 11:06:26.724 | INFO     | utils.common:log:12 - step: 42/100 Loss: 10.1694\10.245 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 41309.4610
2025-07-01 11:06:27.793 | INFO     | utils.common:log:12 - step: 43/100 Loss: 10.1862\10.239 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 45113.8482
2025-07-01 11:06:28.783 | INFO     | utils.common:log:12 - step: 44/100 Loss: 10.1592\10.231 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 56401.1507
2025-07-01 11:06:29.860 | INFO     | utils.common:log:12 - step: 45/100 Loss: 10.1649\10.225 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 45905.4528
2025-07-01 11:06:30.911 | INFO     | utils.common:log:12 - step: 46/100 Loss: 10.1679\10.219 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 46461.2415
2025-07-01 11:06:32.258 | INFO     | utils.common:log:12 - step: 47/100 Loss: 10.1322\10.210 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 37469.9646
2025-07-01 11:06:33.335 | INFO     | utils.common:log:12 - step: 48/100 Loss: 10.1579\10.205 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 39695.0300
2025-07-01 11:06:34.413 | INFO     | utils.common:log:12 - step: 49/100 Loss: 10.1121\10.196 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 53019.5156
2025-07-01 11:06:35.530 | INFO     | utils.common:log:12 - step: 50/100 Loss: 10.1282\10.189 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 38383.3612
2025-07-01 11:06:35.530 | INFO     | utils.common:log:12 - ETA: 00:00:54 
2025-07-01 11:06:36.510 | INFO     | utils.common:log:12 - step: 51/100 Loss: 10.1136\10.181 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 49190.7844
2025-07-01 11:06:37.563 | INFO     | utils.common:log:12 - step: 52/100 Loss: 10.0910\10.172 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 53841.1876
2025-07-01 11:06:38.617 | INFO     | utils.common:log:12 - step: 53/100 Loss: 10.0916\10.164 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 49363.2094
2025-07-01 11:06:39.677 | INFO     | utils.common:log:12 - step: 54/100 Loss: 10.0921\10.157 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 44930.5878
2025-07-01 11:06:40.635 | INFO     | utils.common:log:12 - step: 55/100 Loss: 10.0963\10.151 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 49014.7612
2025-07-01 11:06:41.651 | INFO     | utils.common:log:12 - step: 56/100 Loss: 10.0893\10.145 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 48320.1800
2025-07-01 11:06:42.656 | INFO     | utils.common:log:12 - step: 57/100 Loss: 10.0651\10.137 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 42706.4917
2025-07-01 11:06:43.670 | INFO     | utils.common:log:12 - step: 58/100 Loss: 10.0774\10.131 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 54463.3230
2025-07-01 11:06:44.679 | INFO     | utils.common:log:12 - step: 59/100 Loss: 10.0883\10.127 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 47717.5470
2025-07-01 11:06:45.734 | INFO     | utils.common:log:12 - step: 60/100 Loss: 10.0169\10.116 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 52971.0221
2025-07-01 11:06:45.734 | INFO     | utils.common:log:12 - ETA: 00:00:41 
2025-07-01 11:06:46.750 | INFO     | utils.common:log:12 - step: 61/100 Loss: 10.0520\10.109 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 44834.8651
2025-07-01 11:06:47.760 | INFO     | utils.common:log:12 - step: 62/100 Loss: 10.0602\10.104 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 50031.8492
2025-07-01 11:06:49.247 | INFO     | utils.common:log:12 - step: 63/100 Loss: 10.0186\10.096 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 39854.0532
2025-07-01 11:06:50.261 | INFO     | utils.common:log:12 - step: 64/100 Loss: 10.0331\10.090 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 53645.7622
2025-07-01 11:06:51.235 | INFO     | utils.common:log:12 - step: 65/100 Loss: 10.0320\10.084 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 49898.7426
2025-07-01 11:06:52.301 | INFO     | utils.common:log:12 - step: 66/100 Loss: 9.9758\10.073 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 47715.4555
2025-07-01 11:06:53.380 | INFO     | utils.common:log:12 - step: 67/100 Loss: 10.0147\10.067 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 45766.0741
2025-07-01 11:06:54.432 | INFO     | utils.common:log:12 - step: 68/100 Loss: 10.0329\10.064 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 39426.5869
2025-07-01 11:06:55.449 | INFO     | utils.common:log:12 - step: 69/100 Loss: 10.0058\10.058 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 38487.0848
2025-07-01 11:06:56.559 | INFO     | utils.common:log:12 - step: 70/100 Loss: 9.9775\10.050 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 42761.6989
2025-07-01 11:06:56.559 | INFO     | utils.common:log:12 - ETA: 00:00:31 
2025-07-01 11:06:57.627 | INFO     | utils.common:log:12 - step: 71/100 Loss: 9.9505\10.040 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 46458.0603
2025-07-01 11:06:58.617 | INFO     | utils.common:log:12 - step: 72/100 Loss: 9.9533\10.031 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 52676.6643
2025-07-01 11:06:59.688 | INFO     | utils.common:log:12 - step: 73/100 Loss: 9.9826\10.026 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 47562.7465
2025-07-01 11:07:00.757 | INFO     | utils.common:log:12 - step: 74/100 Loss: 9.9444\10.018 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 51348.4010
2025-07-01 11:07:01.822 | INFO     | utils.common:log:12 - step: 75/100 Loss: 9.9349\10.010 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 46116.6112
2025-07-01 11:07:02.813 | INFO     | utils.common:log:12 - step: 76/100 Loss: 9.9236\10.001 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 50971.3616
2025-07-01 11:07:03.868 | INFO     | utils.common:log:12 - step: 77/100 Loss: 9.9400\9.995 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 44818.3618
2025-07-01 11:07:04.916 | INFO     | utils.common:log:12 - step: 78/100 Loss: 9.9213\9.988 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 48226.6048
2025-07-01 11:07:06.325 | INFO     | utils.common:log:12 - step: 79/100 Loss: 9.9299\9.982 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 37195.9719
2025-07-01 11:07:07.385 | INFO     | utils.common:log:12 - step: 80/100 Loss: 9.9133\9.975 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 45442.7993
2025-07-01 11:07:07.385 | INFO     | utils.common:log:12 - ETA: 00:00:21 
2025-07-01 11:07:08.444 | INFO     | utils.common:log:12 - step: 81/100 Loss: 9.9340\9.971 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 44559.3074
2025-07-01 11:07:09.507 | INFO     | utils.common:log:12 - step: 82/100 Loss: 9.9257\9.966 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 45288.6267
2025-07-01 11:07:10.498 | INFO     | utils.common:log:12 - step: 83/100 Loss: 9.9203\9.962 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 39345.7445
2025-07-01 11:07:11.552 | INFO     | utils.common:log:12 - step: 84/100 Loss: 9.8884\9.954 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 44684.0693
2025-07-01 11:07:12.612 | INFO     | utils.common:log:12 - step: 85/100 Loss: 9.8910\9.948 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 42753.1782
2025-07-01 11:07:13.671 | INFO     | utils.common:log:12 - step: 86/100 Loss: 9.8537\9.939 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 47165.2590
2025-07-01 11:07:14.662 | INFO     | utils.common:log:12 - step: 87/100 Loss: 9.8792\9.933 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 41329.2442
2025-07-01 11:07:15.672 | INFO     | utils.common:log:12 - step: 88/100 Loss: 9.8713\9.927 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 42698.6894
2025-07-01 11:07:16.678 | INFO     | utils.common:log:12 - step: 89/100 Loss: 9.8601\9.920 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 51074.8955
2025-07-01 11:07:17.724 | INFO     | utils.common:log:12 - step: 90/100 Loss: 9.8397\9.912 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 47881.0900
2025-07-01 11:07:17.724 | INFO     | utils.common:log:12 - ETA: 00:00:10 
2025-07-01 11:07:18.736 | INFO     | utils.common:log:12 - step: 91/100 Loss: 9.8416\9.905 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 49791.7951
2025-07-01 11:07:19.747 | INFO     | utils.common:log:12 - step: 92/100 Loss: 9.8332\9.898 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 48450.8535
2025-07-01 11:07:20.747 | INFO     | utils.common:log:12 - step: 93/100 Loss: 9.8290\9.891 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 49611.2765
2025-07-01 11:07:22.053 | INFO     | utils.common:log:12 - step: 94/100 Loss: 9.8109\9.883 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 42695.2495
2025-07-01 11:07:23.068 | INFO     | utils.common:log:12 - step: 95/100 Loss: 9.8123\9.876 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 52293.1294
2025-07-01 11:07:24.081 | INFO     | utils.common:log:12 - step: 96/100 Loss: 9.8004\9.868 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 49106.8956
2025-07-01 11:07:25.086 | INFO     | utils.common:log:12 - step: 97/100 Loss: 9.8047\9.862 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 44415.7998
2025-07-01 11:07:26.092 | INFO     | utils.common:log:12 - step: 98/100 Loss: 9.8455\9.860 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 40454.2020
2025-07-01 11:07:27.156 | INFO     | utils.common:log:12 - step: 99/100 Loss: 9.7765\9.852 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 42572.3674
2025-07-01 11:07:28.252 | INFO     | utils.common:log:12 - step: 100/100 Loss: 9.8043\9.847 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 38095.5266
2025-07-01 11:07:28.252 | INFO     | utils.common:log:12 - ETA: 00:00:00 
2025-07-01 11:07:29.247 | INFO     | utils.common:log:12 - step: 101/100 Loss: 9.7875\9.841 Lr: 1.000e-3 Mem: 43.209 GB Throughput_tokens: 45927.9062
2025-07-01 11:07:29.265 | INFO     | utils.common:log:12 - attain assigned training step 100. Stop Training
Rank 1 stopping training
Rank 0 stopping training
2025-07-01 11:07:29.281 | INFO     | utils.common:log:12 - finish training
2025-07-01 11:07:29.281 | INFO     | utils.common:log:12 - The total Training Time: Avg_time: 1076.9255969238282, Min_time: 959.2218627929688, Max_time: 1667.5181884765625
2025-07-01 11:07:29.327 | INFO     | utils.common:log:12 - Total Time: 00:01:52
